# ClasificaciÃ³n Binaria con PerceptrÃ³n y Redes Neuronales Profundas usando Keras

Este proyecto implementa modelos de redes neuronales para resolver un problema de **clasificaciÃ³n binaria** usando `TensorFlow` y `Keras`. Se exploran tres arquitecturas diferentes: un perceptrÃ³n simple, una red neuronal con una capa oculta, y una red profunda con mÃºltiples capas ocultas.

## ğŸ“ Estructura del Proyecto

â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â””â”€â”€ test.csv
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ model1_perceptron.py
â”‚ â”œâ”€â”€ model2_simple_nn.py
â”‚ â””â”€â”€ model3_deep_nn.py
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ preprocessing.py
â””â”€â”€ main.py

shell
Copiar
Editar

## ğŸ“Œ Objetivo

Construir y comparar diferentes modelos de redes neuronales para un problema de clasificaciÃ³n binaria, evaluando su desempeÃ±o y comportamiento con distintas arquitecturas.

## ğŸ§  Modelos Implementados

### 1. PerceptrÃ³n Simple (`model1_perceptron.py`)
- Una sola neurona con activaciÃ³n sigmoide.
- Arquitectura equivalente a una regresiÃ³n logÃ­stica.

### 2. Red Neuronal con Capa Oculta (`model2_simple_nn.py`)
- Una capa oculta con tantas neuronas como caracterÃ­sticas de entrada.
- Act. sigmoide en capa oculta y salida.

### 3. Red Neuronal Profunda (`model3_deep_nn.py`)
- Tres capas ocultas con 3 neuronas cada una.
- Activaciones sigmoides en cada capa.

## ğŸ› ï¸ TecnologÃ­as Usadas

- Python 3.8+
- TensorFlow/Keras
- NumPy
- Pandas
- Matplotlib (para visualizaciÃ³n)
- Scikit-learn (para mÃ©tricas y preprocesamiento)

## ğŸš€ InstalaciÃ³n

1. Clona el repositorio:

```bash
git clone https://github.com/tu_usuario/tu_repo.git
cd tu_repo
Instala los requisitos:

bash
Copiar
Editar
pip install -r requirements.txt
ğŸ§ª EjecuciÃ³n del Proyecto
bash
Copiar
Editar
python main.py
Este script realiza:

Carga y preprocesamiento de datos.

Entrenamiento de los tres modelos.

EvaluaciÃ³n y comparaciÃ³n con mÃ©tricas de validaciÃ³n.

GrÃ¡ficas de entrenamiento.

ğŸ“Š Resultados
Se registran las mÃ©tricas de accuracy y loss para los tres modelos y se grafican para comparaciÃ³n. La idea es observar cÃ³mo la profundidad afecta la capacidad de aprendizaje del modelo.

ğŸ“ˆ Ejemplo de grÃ¡fico de entrenamiento
python
Copiar
Editar
plt.plot(history1.history['val_accuracy'], label='PerceptrÃ³n')
plt.plot(history2.history['val_accuracy'], label='Red Simple')
plt.plot(history3.history['val_accuracy'], label='Red Profunda')
plt.xlabel('Ã‰pocas')
plt.ylabel('PrecisiÃ³n de ValidaciÃ³n')
plt.title('ComparaciÃ³n de PrecisiÃ³n')
plt.legend()
plt.show()
ğŸ“Œ Consideraciones
Las funciones de activaciÃ³n sigmoid fueron utilizadas en todas las capas ocultas para comparar con un perceptrÃ³n clÃ¡sico, aunque ReLU puede ser mÃ¡s eficiente en redes profundas.

Si el modelo sobreajusta, se recomienda aÃ±adir tÃ©cnicas de regularizaciÃ³n como Dropout o L2.
